{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Qubit-example\" data-toc-modified-id=\"Qubit-example-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Qubit example</a></span></li><li><span><a href=\"#Generating-Data\" data-toc-modified-id=\"Generating-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generating Data</a></span></li><li><span><a href=\"#Creating-the-$\\beta$-VAE\" data-toc-modified-id=\"Creating-the-$\\beta$-VAE-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating the $\\beta$-VAE</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qubit example\n",
    "\n",
    "Here we reproduce the result of tomography qubits from the [Iten and Metger et al. paper](https://arxiv.org/abs/1807.10300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os \n",
    "\n",
    "from Models.VAE_Keras import Dense_VariationalAutoencoder_Keras, Scinet_VariationalAutoencoder_Keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data\n",
    "\n",
    "Data generation taken from [this github repository](https://github.com/eth-nn-physics/nn_physical_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import unitary_group\n",
    "\n",
    "def random_state(qubit_num):\n",
    "    return unitary_group.rvs(2**qubit_num)[:, 0]\n",
    "\n",
    "\n",
    "def random_subspace_states(qubit_num, k, states_num):\n",
    "    \"\"\"\n",
    "    qubit_num: number of qubits\n",
    "    k: number of orthogonal basis vectors\n",
    "    states_num: number of states randomly sampled from subspace\n",
    "    \"\"\"\n",
    "\n",
    "    assert(2 * 2**qubit_num > k)\n",
    "    output_states = []\n",
    "    subspace_basis = (unitary_group.rvs(2**qubit_num)[:, :k]).T\n",
    "    for _ in range(states_num):\n",
    "        c = np.random.rand(k) - 0.5\n",
    "        linear_combination = 0.j\n",
    "        for i in range(k):\n",
    "            linear_combination += c[i] * subspace_basis[i]\n",
    "        output_states.append(linear_combination / np.linalg.norm(linear_combination))\n",
    "    return output_states\n",
    "\n",
    "\n",
    "def projection(a, b):\n",
    "    return np.abs(np.dot(np.conj(a), b))**2\n",
    "\n",
    "\n",
    "def create_data(qubit_num, measurement_num1, measurement_num2, sample_num, file_name=None, incomplete_tomography=[False, False]):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    qubit_num: number of qubits\n",
    "    measurement_num1: number of projective measurements to be performed on input qubit\n",
    "    measurement_num2: number of projective measurements to be performed on projection axis\n",
    "    sample_num: number of training examples to be generated\n",
    "    file_name: file is stored in /data/file_name.pkl.gz\n",
    "    incomplete_tomography: if the i-th entry is k, then the states for the projectors M_i are sampled from a k-dimensional real subspace\n",
    "    \"\"\"\n",
    "    states_in1 = np.empty([sample_num, 2**qubit_num], dtype=np.complex_)\n",
    "    states_in2 = np.empty([sample_num, 2**qubit_num], dtype=np.complex_)\n",
    "    meas_res1 = np.empty([sample_num, measurement_num1], dtype=np.float_)\n",
    "    meas_res2 = np.empty([sample_num, measurement_num2], dtype=np.float_)\n",
    "    output = np.empty([sample_num, 1])\n",
    "    if incomplete_tomography[0]:\n",
    "        fixed_states_in1 = random_subspace_states(qubit_num, incomplete_tomography[0], measurement_num1)\n",
    "    else:\n",
    "        fixed_states_in1 = [random_state(qubit_num) for _ in range(measurement_num1)]\n",
    "        \n",
    "    if incomplete_tomography[1]:\n",
    "        fixed_states_in2 = random_subspace_states(qubit_num, incomplete_tomography[1], measurement_num2)\n",
    "        \n",
    "    else:\n",
    "        fixed_states_in2 = [random_state(qubit_num) for _ in range(measurement_num2)]\n",
    "    for i in range(sample_num):\n",
    "        states_in1[i] = random_state(qubit_num)\n",
    "        states_in2[i] = random_state(qubit_num)\n",
    "        meas_res1[i] = np.array([projection(s1, states_in1[i]) for s1 in fixed_states_in1])\n",
    "        meas_res2[i] = np.array([projection(s2, states_in2[i]) for s2 in fixed_states_in2])\n",
    "        output[i, 0] = projection(states_in1[i], states_in2[i])\n",
    "    result = ([meas_res1, meas_res2, output], [states_in1, states_in2], [fixed_states_in1, fixed_states_in2])\n",
    "    #if file_name is not None:\n",
    "    #    f = gzip.open(io_paths.data_path + file_name + \".plk.gz\", 'wb')\n",
    "    #    cPickle.dump(result, f, protocol=2)\n",
    "    #    f.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation parameters\n",
    "qubit_n = 1\n",
    "meas_num1 = 10\n",
    "meas_num2 = 10\n",
    "samples = 10000\n",
    "\n",
    "validation_size_p = 5 # % of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "data, states, params = create_data(qubit_num=qubit_n, \n",
    "                                measurement_num1=meas_num1, \n",
    "                                measurement_num2=meas_num2, \n",
    "                                sample_num=samples, \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "states = np.array(states)\n",
    "train_val_separation = int(len(data[0]) * (1 - validation_size_p / 100.))\n",
    "training_data = [data[i][:train_val_separation] for i in [0, 1, 2]]\n",
    "training_states = states[:train_val_separation]\n",
    "validation_data = [data[i][train_val_separation:] for i in [0, 1, 2]]\n",
    "validation_states = states[train_val_separation:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the $\\beta$-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = '1_qubit'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "vae = Scinet_VariationalAutoencoder_Keras(\n",
    "    input_dim = (10,)\n",
    "    , encoder_dense_units = [256,128]\n",
    "    , decoder_dense_units = [128,256,1]\n",
    "    , z_dim = 5\n",
    "    , q_dim = (10,)\n",
    ")\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_input (InputLayer)     (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate_Q_Z (Concatenate)   (None, 15)           0           question_input[0][0]             \n",
      "                                                                 decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          2048        Concatenate_Q_Z[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense_0 (Dense)         (None, 128)          16512       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 128)          0           decoder_dense_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense_1 (Dense)         (None, 256)          33024       leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 256)          0           decoder_dense_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense_2 (Dense)         (None, 1)            257         leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1)            0           decoder_dense_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 51,841\n",
      "Trainable params: 51,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Parameters\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1\n",
    "BETA = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR, BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.plot_model(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9500/9500 [==============================] - 2s 194us/step - loss: 0.1369 - vae_r_loss: 0.0849 - vae_kl_loss: 0.0130\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0001_1_qubit/weights/weights-001-0.14.h5\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 2/20\n",
      "9500/9500 [==============================] - 0s 47us/step - loss: 0.0864 - vae_r_loss: 0.0849 - vae_kl_loss: 3.7619e-04\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0001_1_qubit/weights/weights-002-0.09.h5\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 3/20\n",
      "9500/9500 [==============================] - 0s 41us/step - loss: 0.0852 - vae_r_loss: 0.0847 - vae_kl_loss: 1.2593e-04\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0001_1_qubit/weights/weights-003-0.09.h5\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 4/20\n",
      "9500/9500 [==============================] - 1s 53us/step - loss: 0.0849 - vae_r_loss: 0.0846 - vae_kl_loss: 8.2024e-05\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0001_1_qubit/weights/weights-004-0.08.h5\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 5/20\n",
      "9500/9500 [==============================] - 1s 55us/step - loss: 0.0848 - vae_r_loss: 0.0845 - vae_kl_loss: 6.1528e-05\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0001_1_qubit/weights/weights-005-0.08.h5\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 6/20\n",
      "9500/9500 [==============================] - 0s 46us/step - loss: 0.0848 - vae_r_loss: 0.0847 - vae_kl_loss: 4.9158e-05\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0001_1_qubit/weights/weights-006-0.08.h5\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 7/20\n",
      "9500/9500 [==============================] - 0s 42us/step - loss: 0.0846 - vae_r_loss: 0.0844 - vae_kl_loss: 4.1344e-05\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0001_1_qubit/weights/weights-007-0.08.h5\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 8/20\n",
      "9500/9500 [==============================] - 0s 43us/step - loss: 0.0845 - vae_r_loss: 0.0843 - vae_kl_loss: 3.5239e-05\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0001_1_qubit/weights/weights-008-0.08.h5\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 9/20\n",
      "9500/9500 [==============================] - 0s 43us/step - loss: 0.0846 - vae_r_loss: 0.0845 - vae_kl_loss: 3.0251e-05\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0001_1_qubit/weights/weights-009-0.08.h5\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 10/20\n",
      "9500/9500 [==============================] - 0s 44us/step - loss: 0.0844 - vae_r_loss: 0.0843 - vae_kl_loss: 2.6350e-05\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0001_1_qubit/weights/weights-010-0.08.h5\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 11/20\n",
      "9500/9500 [==============================] - 0s 43us/step - loss: 0.0844 - vae_r_loss: 0.0843 - vae_kl_loss: 2.3441e-05\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0001_1_qubit/weights/weights-011-0.08.h5\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 12/20\n",
      "9500/9500 [==============================] - 0s 45us/step - loss: 0.0844 - vae_r_loss: 0.0843 - vae_kl_loss: 2.1224e-05\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0001_1_qubit/weights/weights-012-0.08.h5\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 13/20\n",
      "9500/9500 [==============================] - 0s 41us/step - loss: 0.0844 - vae_r_loss: 0.0844 - vae_kl_loss: 1.9286e-05\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0001_1_qubit/weights/weights-013-0.08.h5\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 14/20\n",
      "9500/9500 [==============================] - 0s 49us/step - loss: 0.0843 - vae_r_loss: 0.0843 - vae_kl_loss: 1.7571e-05\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0001_1_qubit/weights/weights-014-0.08.h5\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 15/20\n",
      "9500/9500 [==============================] - 0s 44us/step - loss: 0.0843 - vae_r_loss: 0.0843 - vae_kl_loss: 1.5904e-05\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0001_1_qubit/weights/weights-015-0.08.h5\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 16/20\n",
      "9500/9500 [==============================] - 0s 47us/step - loss: 0.0843 - vae_r_loss: 0.0843 - vae_kl_loss: 1.4810e-05\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0001_1_qubit/weights/weights-016-0.08.h5\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 17/20\n",
      "9500/9500 [==============================] - 0s 46us/step - loss: 0.0845 - vae_r_loss: 0.0844 - vae_kl_loss: 1.3868e-05\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0001_1_qubit/weights/weights-017-0.08.h5\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 18/20\n",
      "9500/9500 [==============================] - 0s 42us/step - loss: 0.0844 - vae_r_loss: 0.0844 - vae_kl_loss: 1.2958e-05\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0001_1_qubit/weights/weights-018-0.08.h5\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 19/20\n",
      "9500/9500 [==============================] - 0s 47us/step - loss: 0.0843 - vae_r_loss: 0.0842 - vae_kl_loss: 1.2181e-05\n",
      "\n",
      "Epoch 00019: saving model to run/vae/0001_1_qubit/weights/weights-019-0.08.h5\n",
      "\n",
      "Epoch 00019: saving model to run/vae/0001_1_qubit/weights/weights.h5\n",
      "Epoch 20/20\n",
      "9500/9500 [==============================] - 1s 70us/step - loss: 0.0844 - vae_r_loss: 0.0844 - vae_kl_loss: 1.1545e-05\n",
      "\n",
      "Epoch 00020: saving model to run/vae/0001_1_qubit/weights/weights-020-0.08.h5\n",
      "\n",
      "Epoch 00020: saving model to run/vae/0001_1_qubit/weights/weights.h5\n"
     ]
    }
   ],
   "source": [
    "vae.train(     \n",
    "      [training_data[0],training_data[1]]\n",
    "    , training_data[2]\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49004045],\n",
       "       [0.48781648],\n",
       "       [0.4936052 ],\n",
       "       [0.48717928],\n",
       "       [0.50063086],\n",
       "       [0.48710304],\n",
       "       [0.49369344],\n",
       "       [0.4853412 ],\n",
       "       [0.5027831 ],\n",
       "       [0.49945349]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.model.predict([validation_data[0],validation_data[1]])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16750548],\n",
       "       [0.0119015 ],\n",
       "       [0.72617773],\n",
       "       [0.94183377],\n",
       "       [0.03294765],\n",
       "       [0.10024493],\n",
       "       [0.05297095],\n",
       "       [0.39855068],\n",
       "       [0.06903675],\n",
       "       [0.91008374]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[2][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative",
   "language": "python",
   "name": "generative"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
