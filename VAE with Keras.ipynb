{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Variational-Autoencoder-Using-Keras\" data-toc-modified-id=\"Variational-Autoencoder-Using-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Variational Autoencoder Using Keras</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Loading-Data\" data-toc-modified-id=\"Loading-Data-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Loading Data</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder Using Keras\n",
    "\n",
    "The code is based on the book [Generative Deep Learning by David Foster](https://www.oreilly.com/library/view/generative-deep-learning/9781492041931/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from Models.VAE_Keras import VariationalAutoencoder_Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0116 20:01:44.087090 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0116 20:01:44.119557 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0116 20:01:44.139746 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0116 20:01:44.304983 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoencoder_Keras(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,64]#, 64]\n",
    "    , encoder_conv_kernel_size = [3,3,3]#,3]\n",
    "    , encoder_conv_strides = [1,2,2]#,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2\n",
    ")\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 28, 28, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 14, 14, 64)   18496       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 14, 14, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3136)         0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 68,292\n",
      "Trainable params: 68,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Parameters\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 20:01:49.624658 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0116 20:01:52.109563 139686552659776 deprecation_wrapper.py:119] From /home/nahum/anaconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 59.4454 - vae_r_loss: 56.4007 - vae_kl_loss: 3.0447\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0001_digits/weights/weights-001-59.45.h5\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 52.9575 - vae_r_loss: 49.1738 - vae_kl_loss: 3.7838\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0001_digits/weights/weights-002-52.96.h5\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 51.5100 - vae_r_loss: 47.4509 - vae_kl_loss: 4.0591\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0001_digits/weights/weights-003-51.51.h5\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 50.8006 - vae_r_loss: 46.6181 - vae_kl_loss: 4.1825\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0001_digits/weights/weights-004-50.80.h5\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 50.3470 - vae_r_loss: 46.0667 - vae_kl_loss: 4.2803\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0001_digits/weights/weights-005-50.35.h5\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 49.9348 - vae_r_loss: 45.5760 - vae_kl_loss: 4.3589\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0001_digits/weights/weights-006-49.93.h5\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 49.6383 - vae_r_loss: 45.2031 - vae_kl_loss: 4.4352\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0001_digits/weights/weights-007-49.64.h5\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 49.3063 - vae_r_loss: 44.7944 - vae_kl_loss: 4.5119\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0001_digits/weights/weights-008-49.31.h5\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 49.0317 - vae_r_loss: 44.4566 - vae_kl_loss: 4.5751\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0001_digits/weights/weights-009-49.03.h5\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 48.8021 - vae_r_loss: 44.1714 - vae_kl_loss: 4.6308\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0001_digits/weights/weights-010-48.80.h5\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 48.6078 - vae_r_loss: 43.9374 - vae_kl_loss: 4.6704\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0001_digits/weights/weights-011-48.61.h5\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 48.3804 - vae_r_loss: 43.6869 - vae_kl_loss: 4.6936\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0001_digits/weights/weights-012-48.38.h5\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 48.2430 - vae_r_loss: 43.5258 - vae_kl_loss: 4.7172\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0001_digits/weights/weights-013-48.24.h5\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 48.1206 - vae_r_loss: 43.3704 - vae_kl_loss: 4.7502\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0001_digits/weights/weights-014-48.12.h5\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 47.9919 - vae_r_loss: 43.2222 - vae_kl_loss: 4.7698\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0001_digits/weights/weights-015-47.99.h5\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 47.9018 - vae_r_loss: 43.1134 - vae_kl_loss: 4.7885\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0001_digits/weights/weights-016-47.90.h5\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 62603s 1s/step - loss: 47.7819 - vae_r_loss: 42.9764 - vae_kl_loss: 4.8055\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0001_digits/weights/weights-017-47.78.h5\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 280s 5ms/step - loss: 47.7101 - vae_r_loss: 42.8848 - vae_kl_loss: 4.8253\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0001_digits/weights/weights-018-47.71.h5\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 47.6057 - vae_r_loss: 42.7611 - vae_kl_loss: 4.8446\n",
      "\n",
      "Epoch 00019: saving model to run/vae/0001_digits/weights/weights-019-47.61.h5\n",
      "\n",
      "Epoch 00019: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 47.5562 - vae_r_loss: 42.7096 - vae_kl_loss: 4.8466\n",
      "\n",
      "Epoch 00020: saving model to run/vae/0001_digits/weights/weights-020-47.56.h5\n",
      "\n",
      "Epoch 00020: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 47.4617 - vae_r_loss: 42.6080 - vae_kl_loss: 4.8537\n",
      "\n",
      "Epoch 00021: saving model to run/vae/0001_digits/weights/weights-021-47.46.h5\n",
      "\n",
      "Epoch 00021: saving model to run/vae/0001_digits/weights/weights.h5\n",
      "Epoch 22/200\n",
      "39136/60000 [==================>...........] - ETA: 1:20 - loss: 47.3854 - vae_r_loss: 42.5021 - vae_kl_loss: 4.8833"
     ]
    }
   ],
   "source": [
    "vae.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative",
   "language": "python",
   "name": "generative"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
